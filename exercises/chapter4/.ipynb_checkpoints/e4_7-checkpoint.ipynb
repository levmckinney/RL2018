{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\"\"\"\n",
    "S is the set of all possible states\n",
    "R is the set of all possible rewards\n",
    "p(s', r | s, a) is the dynamics\n",
    "list of actions A(s) for all s in S\n",
    "theta is how well to aproximate the true value funtion.\n",
    "\"\"\"\n",
    "def policy_iteration(S:[int], R:[int],p:callable, A:callable, gamma:float, theta:float) -> tuple:\n",
    "    # initalize\n",
    "    V = dict()\n",
    "    pi = dict()\n",
    "    for s in S:\n",
    "        V[s] = 0\n",
    "        pi[s] = 0\n",
    "    \n",
    "    policy_stable = False\n",
    "    while not policy_stable:\n",
    "        # evaluate policy\n",
    "        while True:\n",
    "            delta = 0\n",
    "            for s in tqdm(S):\n",
    "                v = V[s]\n",
    "                V[s] = sum([p(s_,r,s,pi[s]) * (r + gamma*V[s]) for s_, r in product(S, R)])\n",
    "                delta = max(delta, np.abs(v - V[s]))\n",
    "            print(delta)\n",
    "            if delta < theta:\n",
    "                break\n",
    "        \n",
    "        # update policy\n",
    "        policy_stable = True    \n",
    "        for s in S:\n",
    "            old_action = pi[s]\n",
    "            actions = A(s)\n",
    "            pi[s] = actions[\n",
    "                np.argmax(\n",
    "                    sum([p(s_,r,s,a) * (r + gamma*V[s]) for s_, r in product(S, R)]) \n",
    "                for a in actions\n",
    "            )]\n",
    "            if old_action != pi[s]:\n",
    "                policy_stable = False\n",
    "        return pi, V\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected character after line continuation character (<ipython-input-2-aac49ae6017d>, line 36)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-aac49ae6017d>\"\u001b[0;36m, line \u001b[0;32m36\u001b[0m\n\u001b[0;31m    num_end_of_day_lot_2 = next_stat\\e[1] - action\u001b[0m\n\u001b[0m                                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected character after line continuation character\n"
     ]
    }
   ],
   "source": [
    "S = set([(l1,l2) for l1 in range(21) for l2 in range(21)])\n",
    "R = range(0,401, 2)\n",
    "\n",
    "def poisson(n, lamb=1):\n",
    "    return ((lamb ** n)/np.math.factorial(n))*np.exp(-lamb) if n >= 0 else 0\n",
    "\n",
    "\"\"\"\n",
    "Produce possible actions from state s\n",
    "Here s is an ellement of S\n",
    "\"\"\"\n",
    "def actions(s):\n",
    "    return range(-min(5, s[1]), min(5, s[0]) + 1)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "We assume that the action for the last state.\n",
    "last_state: number of cars we have at the two lots\n",
    "action: number of cars we move from lot 1 to lot 2\n",
    "reward: amount we make\n",
    "next state the number of cars we expect to have tomarow\n",
    "\"\"\"\n",
    "def dymanics(next_state, reward, last_state, action) -> float:\n",
    "    if (reward - action*2) % 10 != 0:\n",
    "        # this is not possible since we should have sold a natrual number of cars\n",
    "        return 0\n",
    "    num_sold = (reward - action*2) // 10\n",
    "    # compute the probability\n",
    "    # sum over disjoint events\n",
    "    prob = 0\n",
    "    for sold_at_lot_1 in range(num_sold + 1):\n",
    "        # if we assume the number of cars sold at one lot is fixed then\n",
    "        # we can compute the probability.\n",
    "        # since each one of these events are disjoint we can sum there probabilities.\n",
    "        sold_at_lot_2 = num_sold - sold_at_lot_1\n",
    "        num_end_of_day_lot_1 = next_state[0] + action # we assume this includes the newly arived cars\n",
    "        num_end_of_day_lot_2 = next_state[1] - action\n",
    "        num_arived_lot_1 = num_end_of_day_lot_1 + sold_at_lot_1 - last_state[0]\n",
    "        num_arived_lot_2 = num_end_of_day_lot_2 + sold_at_lot_2 - last_state[1]\n",
    "        prob += (\n",
    "            poisson(sold_at_lot_1, lamb=3)\n",
    "            *poisson(sold_at_lot_2, lamb=4)\n",
    "            *poisson(num_arived_lot_1, lamb=3)\n",
    "            *poisson(num_arived_lot_2, lamb=2))\n",
    "    return prob\n",
    "\n",
    "print(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_iteration(S, R, dymanics, actions, 0.9, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
